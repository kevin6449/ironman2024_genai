{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1_0a1iNComgA6eKZNkyC-zxEpJSmCFOQp",
      "authorship_tag": "ABX9TyOZRdPAPb0J8+vkkQ9DNEfp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kevin6449/ironman2024_genai/blob/main/gen_text_day7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 瞭解 Gemini API 的文件處理功能"
      ],
      "metadata": {
        "id": "4c3TFMFHfRDS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gemini API 可處理傳入的 PDF 文件，並進行推論。時間 上傳 PDF 檔案後，Gemini API 就能：\n",
        "\n",
        "說明或回答內容相關問題\n",
        "提供內容的摘要\n",
        "從內容推斷\n"
      ],
      "metadata": {
        "id": "CyHbqOF0feva"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai"
      ],
      "metadata": {
        "id": "R97GLs0J-8eV"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "API_KEY=userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "TKVTDrPt--uG"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#genai.configure(api_key=\"YOUR_API_KEY\")\n",
        "\n",
        "# Configure the client library by providing your API key.\n",
        "genai.configure(api_key=API_KEY)"
      ],
      "metadata": {
        "id": "Bl_mLa23_EYr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IB_EcA2K_FS6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 使用 File API 上傳文件\n",
        "使用 File API 上傳任何大小的文件。( 想要傳送的檔案與系統指示組合較大 大於 20 MB)。"
      ],
      "metadata": {
        "id": "nYfubU6EfpnI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hA-UQZxh9-fA",
        "outputId": "5e2042f6-c682-4d4d-d464-81bc16ddd232"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 7059k  100 7059k    0     0  16.9M      0 --:--:-- --:--:-- --:--:-- 16.9M\n"
          ]
        }
      ],
      "source": [
        "!curl -o gemini.pdf https://storage.googleapis.com/cloud-samples-data/generative-ai/pdf/2403.05530.pdf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "t-xEdKYzQ8O_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "使用 media.upload 和 輸出 URI，此 URI 在 Gemini API 呼叫中會用做參考：\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_cS10WlOf9Mz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload the file and print a confirmation\n",
        "sample_file = genai.upload_file(path=\"gemini.pdf\",\n",
        "                                display_name=\"Gemini 1.5 PDF\")\n",
        "\n",
        "print(f\"Uploaded file '{sample_file.display_name}' as: {sample_file.uri}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "2nVUs1AH_X7n",
        "outputId": "df143552-3084-41fb-82cd-58ec3acf9a6c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploaded file 'Gemini 1.5 PDF' as: https://generativelanguage.googleapis.com/v1beta/files/q5sm8ac67ph8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 驗證 PDF 檔案上傳及取得中繼資料\n",
        "您可以驗證 API 是否已成功儲存上傳的檔案，並取得其 透過 SDK 呼叫 files.get 來更新中繼資料僅限 name (及 副檔名為 uri) 重複。只有在符合以下條件時，才使用「display_name」來識別檔案 以及自己的特色\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YdTqneLPgA2n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file = genai.get_file(name=sample_file.name)\n",
        "print(f\"Retrieved file '{file.display_name}' as: {sample_file.uri}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vtYuaaFo_cJa",
        "outputId": "57e504fe-64c1-441e-f4f6-cb0e2b93538c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieved file 'Gemini 1.5 PDF' as: https://generativelanguage.googleapis.com/v1beta/files/q5sm8ac67ph8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 使用上傳的文件，提示 Gemini API\n",
        "上傳檔案後，您可以提出參照的 GenerateContent 要求 File API URI選取生成式模型，並以文字提示提供模型 以及上傳的文件：\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "X1OIdC7wgHEk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose a Gemini model.\n",
        "model = genai.GenerativeModel(model_name=\"gemini-1.5-flash\")\n",
        "\n",
        "# Prompt the model with text and the previously uploaded image.\n",
        "response = model.generate_content([sample_file, \"您能否將這份文件總結為項目符號清單？\"])\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "id": "XKjpMbvG_jtR",
        "outputId": "48c3970f-8f3d-4e29-9674-0c5d46f1decc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "當然可以。以下是文件的摘要：\n",
            "\n",
            "* **簡介**。這篇文章介紹了 Gemini 1.5 Pro，這是 Google DeepMind 所開發的一種新的多模態混合專家模型，能夠處理超過 1000 萬個標記的上下文。\n",
            "* **模型架構**。Gemini 1.5 Pro 是基於稀疏混合專家 (MoE) 轉換器的，並建立在 Google 在 MoE 模型和語言模型研究上的過去工作之上。\n",
            "* **訓練基礎架構和數據集**。Gemini 1.5 Pro 訓練於多個 4096 芯片的 Google TPUv4 加速器，這些加速器分佈在多個數據中心，並使用多模態和多語言數據。\n",
            "* **長上下文評估**。由於模型的長上下文能力，研究人員對模型進行了大型定量評估，包括針對長序列的困惑度，以及「乾草堆中的針」任務。\n",
            "* **現實長上下文評估**。研究人員通過新的任務來評估模型，這些任務需要更長更真實的上下文，例如從單本書中學習翻譯新語言。\n",
            "* **核心能力評估**。研究人員評估了模型在沒有長上下文設置的情況下在核心能力方面的表現，例如數學、科學和推理，編碼，多語言，以及指令遵循。\n",
            "* **負責任的部署**。研究人員遵循一個結構化的方法，在 Gemini 模型的部署中考慮倫理和安全問題。\n",
            "* **討論**。文章討論了長上下文評估的挑戰，以及在未來發展中使用更先進的長上下文模型的重要性。\n",
            "\n",
            "希望這個摘要有幫助！\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 上傳一或多個儲存在本機的檔案\n",
        "或者，您也可以上傳一或多個本機儲存的檔案。\n",
        "\n",
        "如果您打算傳送的檔案和系統指示組合， 如果超過 20 MB，請使用 File API 上傳這些檔案 。使用者可透過 Gemini API 在本機呼叫較小的檔案："
      ],
      "metadata": {
        "id": "g0xyQJ9ZgUp1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yA8f7ARSvpC",
        "outputId": "d249e6a3-71b0-4ca0-e77c-b910b06cee60"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import PyPDF2\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    with open(pdf_path, 'rb') as pdf_file:\n",
        "        pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
        "        extracted_text = \"\"\n",
        "        for page in pdf_reader.pages:\n",
        "            text = page.extract_text()\n",
        "            if text:\n",
        "                extracted_text += text\n",
        "        return extracted_text\n",
        "\n",
        "sample_file_2 = extract_text_from_pdf('/content/drive/MyDrive/OWASP_Top_10-2017_(en).pdf.pdf')\n",
        "#sample_file_3 = extract_text_from_pdf('example-2.pdf')"
      ],
      "metadata": {
        "id": "SaWd52Me_2Xi"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 顯示多份文件的提示\n",
        "您與 Gemini API 的任何文件和文字組合都可以用於 會套用在模型的背景區間內這個範例提供一則簡短文字 提示和先前上傳的n份文件："
      ],
      "metadata": {
        "id": "WK2GAGzVgaKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose a Gemini model.\n",
        "model = genai.GenerativeModel(model_name=\"gemini-1.5-pro\")\n",
        "\n",
        "prompt = \"各用100字總結列出這兩份的論文的陳述,請用繁體中文回答\"\n",
        "\n",
        "response = model.generate_content([prompt, sample_file_2, sample_file])\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "G6fegemzABEc",
        "outputId": "7cd41fb8-7e3d-44e4-9905-eb1f22a2effb"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## 兩份論文陳述總結：\n",
            "\n",
            "**第一份論文：**\n",
            "\n",
            "**OWASP Top 10 - 2017** 重點闡述了十大最嚴重的 Web 應用程序安全風險，包括注入、失效的身份驗證、敏感數據洩露、XML 外部實體 (XXE)、失效的訪問控制、安全配置錯誤、跨站腳本 (XSS)、不安全的反序列化、使用已知漏洞的組件，以及不足的日誌記錄和監控。這份文件基於 40 多家應用程序安全公司的數據提交和 500 多人的行業調查，旨在提高開發人員和組織對這些風險的認識，並提供防範措施和下一步行動建議。\n",
            "\n",
            "**第二份論文：**\n",
            "\n",
            "**Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context** 介绍了最新的多模態模型 Gemini 1.5 Pro。該模型採用混合專家架構，能理解長達千萬級別 token 的上下文，包括長文檔、長視頻和長音頻。論文展示了 Gemini 1.5 Pro 在長上下文理解方面的優異性能，例如在長文檔問答、長視頻問答和長上下文語音識別方面的表現。同時，該模型還展示了從單一語言學資料學習新語言的能力，例如僅通過語法手冊就能學會將英語翻譯成僅有 200 人使用的 Kalamang 語言。 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 可列出檔案\n",
        "您可以使用 File API 列出透過 File API 上傳的所有檔案及其 URI files.list_files():"
      ],
      "metadata": {
        "id": "uKdabQM8ghrL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List all files\n",
        "for file in genai.list_files():\n",
        "    print(f\"{file.display_name}, URI: {file.uri}\")"
      ],
      "metadata": {
        "id": "LbQZl1SEABzU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 刪除檔案\n",
        "使用 File API 上傳的檔案會在 2 天後自動刪除。個人中心 您也可以使用 files.delete_file() 手動刪除：\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FtnydTZWgnqg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete file\n",
        "genai.delete_file(document_file.name)\n",
        "print(f'Deleted file {document_file.uri}')"
      ],
      "metadata": {
        "id": "ZDzFiZ1GAFJ5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}